{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LotusBro98/Lanat2019/blob/master/Machine_Learning_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWk1uON6fKQa",
        "colab_type": "text"
      },
      "source": [
        "# Машинное обучение\n",
        "## Генеративные состязательные сети\n",
        "\n",
        "---\n",
        "\n",
        "<img width=\"100%\" src=\"https://pa1.narvii.com/6910/9641f0ed17e10ad698e4e9c23a3de25550339fc5r1-811-397_hq.gif\">\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPhkhNr6lDp7",
        "colab_type": "text"
      },
      "source": [
        "В данном примере будет рассмотрена архитектура DCGAN для генерации Pixel Art персонажей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB2uz6sFfPes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFyq_0lsroRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whWUYLRysq5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SIZE = 64\n",
        "MAX_IMAGES = 1000\n",
        "OUTPUT_CHANNELS = 4\n",
        "N_INPUT_PARAMS = 512\n",
        "BATCH_SIZE = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q19LS6k7lnsn",
        "colab_type": "text"
      },
      "source": [
        "## Загрузим и подготовим датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb66xEwoe5P1",
        "colab_type": "text"
      },
      "source": [
        "Поместите изображения на свой Google Диск в папку \"Мой Диск/pixelartgen/images\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EegzwoE1n1zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "app_dir = \"/content/drive/My Drive/pixelartgen\"\n",
        "!mkdir -p \"{app_dir}\"\n",
        "os.chdir(app_dir)\n",
        "\n",
        "img_dir = \"images\"\n",
        "!mkdir -p \"{img_dir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JCRNL6-oj0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(filename):\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.io.decode_image(image, channels=4)\n",
        "\n",
        "  h, w = image.shape[:2]\n",
        "  if w > h:\n",
        "    offset_h = (w - h) // 2\n",
        "    offset_w = 0\n",
        "  else:\n",
        "    offset_h = 0\n",
        "    offset_w = (h - w) // 2\n",
        "\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = image / 255.0\n",
        "\n",
        "  image = tf.image.pad_to_bounding_box(image, offset_h, offset_w, max(w, h), max(w, h))\n",
        "  alpha_1 = tf.ones_like(image)\n",
        "  alpha_1 = tf.transpose(alpha_1, (2, 0, 1))\n",
        "\n",
        "  image = tf.transpose(image, (2, 0, 1))\n",
        "  image = image * image[-1] + alpha_1 * (1.0 - image[-1])\n",
        "  image = tf.transpose(image, (1, 2, 0))\n",
        "\n",
        "  image = tf.image.resize(image, (SIZE, SIZE), method='nearest')\n",
        "  image = image * 2 - 1\n",
        "\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lebJSCmrzni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = glob.glob(os.path.join(img_dir, \"*.*\"))\n",
        "files = files[:MAX_IMAGES]\n",
        "train_images = list(map(load_image, files))\n",
        "train_images = tf.stack(train_images)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "print(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFhj5kLui2t",
        "colab_type": "text"
      },
      "source": [
        "### Отобразим несколько картинок из датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajQCcgVRuhBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_PLOTS = 4\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(N_PLOTS * N_PLOTS):\n",
        "  plt.subplot(N_PLOTS, N_PLOTS, i + 1)\n",
        "  plt.imshow(random.choice(train_images) * 0.5 + 0.5)\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEm1RFGJv3WK",
        "colab_type": "text"
      },
      "source": [
        "## Определим модель генератора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsVLqLXwvQDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(x, filters, size=5):\n",
        "    x = layers.Conv2DTranspose(filters, (size, size), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    return x\n",
        "\n",
        "def make_generator_model():\n",
        "    inputs = layers.Input(shape=(N_INPUT_PARAMS,))\n",
        "    x = inputs\n",
        "\n",
        "    x = layers.Dense(512, use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Reshape((1, 1, 512))(x)\n",
        "\n",
        "    x = upsample(x, 256)     # 2 x 2 x 256\n",
        "    x = upsample(x, 128)     # 4 x 4 x 128\n",
        "    x = upsample(x, 64)      # 8 x 8 x 64\n",
        "    x = upsample(x, 32)      # 16 x 16 x 32\n",
        "    x = upsample(x, 16)      # 32 x 32 x 16\n",
        "    x = upsample(x, 8)       # 64 x 64 x 8\n",
        "\n",
        "    x = layers.Conv2DTranspose(OUTPUT_CHANNELS, (5, 5), padding='same', use_bias=False, activation='tanh')(x)\n",
        "                             # 64 x 64 x 4\n",
        "                             \n",
        "    assert tuple(x.shape) == (None, SIZE, SIZE, OUTPUT_CHANNELS)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMPKyvb7R1yZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(x, filters, size=5):\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    return x\n",
        "\n",
        "def make_discriminator_model():\n",
        "    inputs = layers.Input(shape=(SIZE, SIZE, OUTPUT_CHANNELS))\n",
        "    x = inputs\n",
        "\n",
        "    x = downsample(x, 16)     # 32 x 32 x 16\n",
        "    x = downsample(x, 32)     # 16 x 16 x 32\n",
        "    x = downsample(x, 64)     # 8 x 8 x 64\n",
        "    x = downsample(x, 128)    # 4 x 4 x 128 \n",
        "    x = downsample(x, 256)    # 2 x 2 x 256\n",
        "    x = downsample(x, 512)    # 1 x 1 x 512  \n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf8oyg-SNpXR",
        "colab_type": "text"
      },
      "source": [
        "## Определим лосс-функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lxvBO6LNz_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Thc4FCN3mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6zVadbxN54S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgpB_ltMN-ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPatnb85OMne",
        "colab_type": "text"
      },
      "source": [
        "## Приступим к обучению"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51yP0u9KOn46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([N_PLOTS * N_PLOTS, N_INPUT_PARAMS])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDOkx31WOL51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, N_INPUT_PARAMS])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPb1VoZOQ9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    if (epoch + 1) % 200 == 0:\n",
        "      # Produce images for the GIF as we go\n",
        "      display.clear_output(wait=True)\n",
        "      generate_and_save_images(seed, epoch)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 10000 == 0:\n",
        "      generator.save(\"generator.h5\")\n",
        "      discriminator.save(\"discriminator.h5\")\n",
        "\n",
        "    sys.stdout.write('\\rTime for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPCOnH_sO4hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p gen\n",
        "\n",
        "def generate_and_save_images(test_input, epoch):\n",
        "  generated = generator(test_input)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(N_PLOTS * N_PLOTS):\n",
        "    plt.subplot(N_PLOTS, N_PLOTS, i + 1)\n",
        "    plt.imshow(generated[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "  plt.savefig('gen/image_at_epoch_{:04d}.png'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkC-81auPuGs",
        "colab_type": "text"
      },
      "source": [
        "## Обучаем!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKdlRxYqX2e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg8jQgaDXQd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Восстанавливаем сохраненную модель, если она есть\n",
        "try:\n",
        "  generator.load_weights(\"generator.h5\")\n",
        "  discriminator.load_weights(\"discriminator.h5\")\n",
        "  print(\"Restored\")\n",
        "except:\n",
        "  print(\"Failed to restore. Starting all over\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59EcgULmYGtt",
        "colab_type": "text"
      },
      "source": [
        "### И вот теперь наконец обучаем!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ikVQEJ8Pto1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10000\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}